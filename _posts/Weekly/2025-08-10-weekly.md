---
title: 2025-08-10 週記
layout: post
category: Weekly
image:
date: 2025-08-10
---
預測 TGA 2025 
- 年度遊戲、音樂、美術、獨立遊戲：33 遠征隊  
- 指導、敘事、角色扮演：死亡擱淺 2  
	- （角色扮演我覺得也有可能是天國降臨 2）  
- 最佳演出：Higgs 的演員 Troy Baker

## 推薦 Reddit

最近喜歡泡在 Reddit 上，特別是一些諸如 homelab、meshtactic 之類的小型技術網站，令我感興趣的貼文相較於 Twitter 密集，畢竟在 Twitter 追縱的是人而在 Reddit 上是主題。然後再關注幾個高品質的新聞或聚合網站充當隨機性來源，例如我是 HackerNews 搭配華爾街日報，基本上科技及政治大事就都有了。

所謂隨機性來源是打破同溫層的意思。不過政治上的「非同溫層」我興趣不大，主要還是平常沒接觸到的電玩作品或有趣的科技產品。Reddit 上的電玩社群我倒是沒有加入，最主要的原因時候很多人會在上面問攻略。

## 試玩 GPT-OSS

用 GPT-o3 上網搜尋論文再生成了一些困難的醫學知識問題 - 大部分都是次專科等級的（間質性肺病、孕婦自體免疫） - 來看看 GPT-OSS 120B 的程度如何。結果所有問題都可以答對 - 而且可以具體指出是哪個 trial。這個知識量跟 recall 的能力真驚人！遠遠超越當年的 GPT-3.5，而這樣的模型居然能輕易的跑在我的 Mac Studio 裡面。

是說 GPT-5 也是這週發佈。劇本運作的速度比 AI 2027 預估的還快，每兩個月就有一批新的、可怕的工具出現，比方說：

- ChatGPT deep research 是二月才發布的（Gemini 則是一月多）
- Codex 跟 Claude Code 是五月發布的（CC 二月是預覽版）
- GPT-o3 是四月發布的，四個月後隨即被 GPT-5 掃入歷史的垃圾桶

當然有人拿一些 LLM 至今似乎還沒辦法克服的軟肋去表達「模型錯誤很多」。例如要模型去算求解 $5.9 = x + 5.11$ 這一類的問題。我個人覺得沒有什麼意義，LLM 的架構就是那樣，你不可能要一個 Transformer 展現全部的人類智能；我個人認為主要進步還是讓 LLM 可以編寫外部程式處理這些問題，例如數學計算或計數等問題。

| 模型               | 代表性基準與定位                                          | 部署/硬體要點                                      |
| ---------------- | ------------------------------------------------- | -------------------------------------------- |
| gpt-oss-120B     | 官方稱推理基準接近 o4-mini；面向一般高推理任務                       | 可單張 80 GB H100 佈署；Apache-2.0 易商用與再訓練         |
| Kimi K2          | SWE-Bench Verified 65.8%（SOTA 級別的開源非思維模型）；代理/工具鏈強 | 1T/32B-active 的 MoE，雲端供應商支援 128K 以上情境與工具使用   |
| DeepSeek-R1 / V3 | R1 在數學、程式推理接近 o1 等級；性價比高                          | 128K 情境；MIT 授權，易於二次開發與蒸餾部署                   |
| Qwen（2.5/3）      | 72B dense 與 235B-A22B MoE 在通用任務與多語系表現強；家族齊全       | 普遍 128K；Apache-2.0；A22B 22B-active 具低延遲優勢    |
| Llama 4          | 原生多模態、極長上下文（Scout 10M）；社群生態完備                     | 社群授權具大型用戶限制                                  |
| Gemma 3          | 同尺寸表現強、邊緣/單 GPU 友善；多模態輸入                          | 1–27B 輕量段位；128K（1B 為 32K）；License 較開放但仍有條款限制 |